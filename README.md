# CULytics2020 - Explaining Explainable AI

Alliant Credit Union launched its data science program in 2019 after some successful Proof of Concepts. ACU hired data scientists as well as brought in tools and technology to assist with the program development. At the same time, ACU crossed the $10B threshold introducing a lot of new regulatory constraints. With the crossing of the threshold came burden on documentation processes and more regulatory scrutiny.

While Alliant has long had modeling for credit risk, data science and machine learning was new to the organization. With the data science function, the team transitioned to more advanced modeling techniques such as gradient boosted decision trees and neural networks.  These models are complex to understand and often hard to interpret how they make decisions. Many people familiar with traditional statistical methodologies such as linear and logistic regression are accustom to a certain level of model interpretability and explainability.  To build trust in the models, the ACU data science team started exploring explainability techniques. These techniques help bridge the gaps between modelers and stakeholders.

The presentation examines:
* What explainable AI is and why itâ€™s important
* The difference between local and global feature importance and why it matters
* How a linear regression model is different from a gradient boosted decision tree
* Popular explainability techniques including:
  - LIME
  - SHAP
  - InterpretML
* Decision flow to determine the right level of interpretability
 
This repo will store the presentation and associated jupyter notebooks with sample code written in Python.
